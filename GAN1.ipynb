{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN1",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "79bEeyGhvvcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajg_2D0YxiA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4bccff17-2387-4987-e935-546ae7e3a80b"
      },
      "cell_type": "code",
      "source": [
        "# Installing required libraries\n",
        "! pip install torch torchvision tensorboardx"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.6/dist-packages (1.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx) (3.7.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardx) (40.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LqjmR07qx3W3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd.variable import Variable\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xVIkTgUWyLYA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mnist_data():\n",
        "  \n",
        "  compose = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "  out_dir = './dataset'\n",
        "  \n",
        "  return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lendazovA1Ga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = mnist_data()\n",
        "\n",
        "# Creating data loader\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
        "\n",
        "num_batches = len(data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XKtu1lpRC3nI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Discriminator Class\n",
        "\n",
        "class DiscriminatorNet(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    super(DiscriminatorNet, self).__init__()\n",
        "    n_features = 784\n",
        "    n_out = 1\n",
        "    \n",
        "    self.hidden0 = nn.Sequential(nn.Linear(n_features, 1024), nn.LeakyReLU(0.2), nn.Dropout(0.3))\n",
        "    \n",
        "    self.hidden1 = nn.Sequential(nn.Linear(1024, 512), nn.LeakyReLU(0.2), nn.Dropout(0.3))\n",
        "    \n",
        "    self.hidden2 = nn.Sequential(nn.Linear(512, 256), nn.LeakyReLU(0.2), nn.Dropout(0.3))\n",
        "    \n",
        "    self.out = nn.Sequential(nn.Linear(256, n_out), nn.LeakyReLU(0.2), nn.Dropout(0.3))\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    \n",
        "    x = self.hidden0(x)\n",
        "    x = self.hidden1(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = self.out(x)\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZhQEQcBRqat",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Object of Discriminator class initialised\n",
        "\n",
        "discriminator = DiscriminatorNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CSot_HLQR5ZL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Functions to convert images to vectors and vice-versa\n",
        "\n",
        "def images_to_vectors(images):\n",
        "  return images.view(images.size(0), 784)\n",
        "\n",
        "def vectors_to_images(vectors):\n",
        "  return vectors.view(vectors.size(0), 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Pv7U4BiSqaS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generator Class\n",
        "\n",
        "class GeneratorNet(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    \n",
        "    super(GeneratorNet, self).__init__()\n",
        "    n_features = 100\n",
        "    n_out = 784\n",
        "    \n",
        "    self.hidden0 = nn.Sequential(nn.Linear(n_features, 256), nn.LeakyReLU(0.2))\n",
        "    \n",
        "    self.hidden1 = nn.Sequential(nn.Linear(256, 512), nn.LeakyReLU(0.2))\n",
        "    \n",
        "    self.hidden2 = nn.Sequential(nn.Linear(512, 1024), nn.LeakyReLU(0.2))\n",
        "    \n",
        "    self.out = nn.Sequential(nn.Linear(1024, n_out), nn.Tanh())\n",
        "    \n",
        "  \n",
        "  def forward(self, x):\n",
        "    \n",
        "    x = self.hidden0(x)\n",
        "    x = self.hidden1(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = self.out(x)\n",
        "    \n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6CG3jS6hfXE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generator Object Initialised\n",
        "generator = GeneratorNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NWKwkWxfgtX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Introducing some random noise sampled from a normal distribution \n",
        "# with mean 0 and variance 1\n",
        "\n",
        "def noise(size):\n",
        "  \n",
        "  n = Variable(torch.randn(size, 100))\n",
        "  \n",
        "  return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m-WeRD3ygxEc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Optimizers for both generator and discriminator\n",
        "\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gwKKcm9rhFwk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Binary Cross Entropy Loss Function\n",
        "\n",
        "loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DzeDUBLlhRxq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ones_target(size):\n",
        "  \n",
        "  data = Variable(torch.ones(size, 1))\n",
        "  \n",
        "  return data\n",
        "\n",
        "def zeroes_target(size):\n",
        "  \n",
        "  data = Variable(torch.zeros(size, 1))\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F30aEP1Eigvp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Discriminator\n",
        "\n",
        "def  train_discriminator(optimizer, real_data, fake_data):\n",
        "  \n",
        "  N = real_data.size(0)\n",
        "  optimizer.zero_grad()  # Reset Gradients\n",
        "  \n",
        "  # Training on Real Data\n",
        "  \n",
        "  prediction_real = discriminator(real_data)\n",
        "  error_real = loss(prediction_real, ones_target(N)) # Calculating Error\n",
        "  error_real.backward()   # Backpropagation\n",
        "  \n",
        "  \n",
        "  # Training on Fake Data\n",
        "  \n",
        "  prediction_fake = discriminator(fake_data)\n",
        "  error_fake = loss(prediction_fake, zeroes_target(N))  # Calculating Error\n",
        "  error_fake.backward()    # Backpropagation\n",
        "  \n",
        "  \n",
        "  # Updating Weights\n",
        "  \n",
        "  optimizer.step()\n",
        "  \n",
        "  return error_real + error_fake, prediction_real, prediction_fake\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7z8U69YtkHbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Generator \n",
        "\n",
        "def train_generator(optimizer, fake_data):\n",
        "  \n",
        "  N = fake_data.size(0)\n",
        "  \n",
        "  \n",
        "  optimizer.zero_grad()  # Reset Gradients\n",
        "  \n",
        "  prediction = discriminator(fake_data)\n",
        "  \n",
        "  error = loss(prediction, ones_target(N))\n",
        "  error.backward()\n",
        "  \n",
        "  optimizer.step()\n",
        "  \n",
        "  return error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jeo0PyP4lRqR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "num_test_samples = 16\n",
        "test_noise = noise(num_test_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pzay2t37lt4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import errno\n",
        "import torchvision.utils as vutils\n",
        "from tensorboardX import SummaryWriter\n",
        "from IPython import display\n",
        "\n",
        "'''\n",
        "    TensorBoard Data will be stored in './runs' path\n",
        "'''\n",
        "\n",
        "\n",
        "class Logger:\n",
        "\n",
        "    def __init__(self, model_name, data_name):\n",
        "        self.model_name = model_name\n",
        "        self.data_name = data_name\n",
        "\n",
        "        self.comment = '{}_{}'.format(model_name, data_name)\n",
        "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
        "\n",
        "        # TensorBoard\n",
        "        self.writer = SummaryWriter(comment=self.comment)\n",
        "\n",
        "    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
        "\n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/D_error'.format(self.comment), d_error, step)\n",
        "        self.writer.add_scalar(\n",
        "            '{}/G_error'.format(self.comment), g_error, step)\n",
        "\n",
        "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
        "        '''\n",
        "        input images are expected in format (NCHW)\n",
        "        '''\n",
        "        if type(images) == np.ndarray:\n",
        "            images = torch.from_numpy(images)\n",
        "        \n",
        "        if format=='NHWC':\n",
        "            images = images.transpose(1,3)\n",
        "        \n",
        "\n",
        "        step = Logger._step(epoch, n_batch, num_batches)\n",
        "        img_name = '{}/images{}'.format(self.comment, '')\n",
        "\n",
        "        # Make horizontal grid from image tensor\n",
        "        horizontal_grid = vutils.make_grid(\n",
        "            images, normalize=normalize, scale_each=True)\n",
        "        # Make vertical grid from image tensor\n",
        "        nrows = int(np.sqrt(num_images))\n",
        "        grid = vutils.make_grid(\n",
        "            images, nrow=nrows, normalize=True, scale_each=True)\n",
        "\n",
        "        # Add horizontal images to tensorboard\n",
        "        self.writer.add_image(img_name, horizontal_grid, step)\n",
        "\n",
        "        # Save plots\n",
        "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
        "\n",
        "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "\n",
        "        # Plot and save horizontal\n",
        "        fig = plt.figure(figsize=(16, 16))\n",
        "        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        if plot_horizontal:\n",
        "            display.display(plt.gcf())\n",
        "        self._save_images(fig, epoch, n_batch, 'hori')\n",
        "        plt.close()\n",
        "\n",
        "        # Save squared\n",
        "        fig = plt.figure()\n",
        "        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
        "        plt.axis('off')\n",
        "        self._save_images(fig, epoch, n_batch)\n",
        "        plt.close()\n",
        "\n",
        "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
        "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n",
        "                                                         comment, epoch, n_batch))\n",
        "\n",
        "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
        "        \n",
        "        # var_class = torch.autograd.variable.Variable\n",
        "        if isinstance(d_error, torch.autograd.Variable):\n",
        "            d_error = d_error.data.cpu().numpy()\n",
        "        if isinstance(g_error, torch.autograd.Variable):\n",
        "            g_error = g_error.data.cpu().numpy()\n",
        "        if isinstance(d_pred_real, torch.autograd.Variable):\n",
        "            d_pred_real = d_pred_real.data\n",
        "        if isinstance(d_pred_fake, torch.autograd.Variable):\n",
        "            d_pred_fake = d_pred_fake.data\n",
        "        \n",
        "        \n",
        "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n",
        "            epoch,num_epochs, n_batch, num_batches)\n",
        "             )\n",
        "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
        "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
        "\n",
        "    def save_models(self, generator, discriminator, epoch):\n",
        "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
        "        Logger._make_dir(out_dir)\n",
        "        torch.save(generator.state_dict(),\n",
        "                   '{}/G_epoch_{}'.format(out_dir, epoch))\n",
        "        torch.save(discriminator.state_dict(),\n",
        "                   '{}/D_epoch_{}'.format(out_dir, epoch))\n",
        "\n",
        "    def close(self):\n",
        "        self.writer.close()\n",
        "\n",
        "    # Private Functionality\n",
        "\n",
        "    @staticmethod\n",
        "    def _step(epoch, n_batch, num_batches):\n",
        "        return epoch * num_batches + n_batch\n",
        "\n",
        "    @staticmethod\n",
        "    def _make_dir(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mLA8Rwa1mMX-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating a Logger instance\n",
        "logger = Logger(model_name='VGAN', data_name='MNIST')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oI4WRiKlmiK0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Num of epochs to train\n",
        "num_epochs = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mfyn7_bTmnU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  \n",
        "  for n_batch, (real_batch,_) in enumerate(data_loader):\n",
        "    N = real_batch.size(0)\n",
        "    \n",
        "    # Train Discriminator\n",
        "    real_data = Variable(images_to_vectors(real_batch))\n",
        "    \n",
        "    # Generate fake data and detach\n",
        "    fake_data = generator(noise(N)).detach()\n",
        "    \n",
        "    #Train D\n",
        "    d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer, real_data, fake_data)\n",
        "    \n",
        "    \n",
        "    # Train Generator\n",
        "    fake_data = generator(noise(N))\n",
        "    \n",
        "    # Train G\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}